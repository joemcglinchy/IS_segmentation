{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/spatial_torch/lib/python3.5/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/spatial_torch/lib/python3.5/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/spatial_torch/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/spatial_torch/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/spatial_torch/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import glob\n",
    "import os,sys\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import fiona\n",
    "from shapely.geometry import shape\n",
    "import shapely\n",
    "from rasterio.mask import mask\n",
    "from pyproj import Proj, transform\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from unet_models import unet11\n",
    "\n",
    "from test_unet_helpers import calcXYfromRC, checkWindow, gtDatasetSampler2, DigitalGlobeSamplerTensor\n",
    "\n",
    "from utils import variable\n",
    "from scipy import misc\n",
    "\n",
    "from gbdxtools import Interface, CatalogImage\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify scene id for DG data\n",
    "dg_scene_id = '1030010057062200' # 2016\n",
    "dg_scene_id = '104001000AA4B500' # 2015\n",
    "dg_scene_id = '103001001A425F00' #napoli 2011\n",
    "\n",
    "# specify image for 2.0 meter analysis\n",
    "gt_image_2 = '../rasters/union_impervious_raster_2_0_0_wgs84.tif' # desktop\n",
    "\n",
    "# specify images for 0.5 meter analysis\n",
    "gt_image_05 = '../rasters/union_impervious_raster_0_5.tif' # desktop\n",
    "\n",
    "# specify the shapefile\n",
    "shpfile = '../union/union.shp' # desktop\n",
    "\n",
    "with fiona.open(shpfile) as shp:\n",
    "    crs = shp.crs\n",
    "    shp_bounds = shp.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(img_2m, axis=(1,2)).compute(), np.std(img_2m, axis=(1,2)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_2m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to gbdx\n",
    "gbdx = Interface()\n",
    "\n",
    "# get the dask array for the 8 band MS image\n",
    "img_2m = CatalogImage(dg_scene_id, band_type='MS', bbox=shp_bounds, acomp=True)\n",
    "rows, cols = img_2m.shape[1:]\n",
    "\n",
    "np.mean(img_2m, axis=(1,2)).compute(), np.std(img_2m, axis=(1,2)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify image transform for RGB image\n",
    "img_transform = Compose([\n",
    "    Normalize(mean=[1630.7322, 1574.9552, 1549.1031], std=[837.0847 , 766.4114 , 604.51605])\n",
    "])\n",
    "\n",
    "# for 2015\n",
    "img_transform = Compose([\n",
    "    Normalize(mean=[1281.2312, 1243.6267, 1334.2975], std=[645.607, 703.0832, 862.68665])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and the model state from the .pt file. It may need to be downloaded from AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model, epoch 44, step 537\n"
     ]
    }
   ],
   "source": [
    "model_path = 'runs/debug/model_e100_b32_no_aug_GPUPAR.pt' # RGB batch size 32\n",
    "model_path = 'runs/debug/model_e100_b8_no_aug_GPUPAR.pt' # RGB batch size 8\n",
    "model_path = 'runs/debug/MS_model_e100_b8_no_aug_GPUPAR.pt' # MS model\n",
    "model_path = 'runs/debug/model_e44_s34938.pt' # RGB early exit (large batch size, i think)\n",
    "\n",
    "model = unet11(pretrained=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # get device for gpu or cpu\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    \n",
    "elif torch.cuda.is_available():\n",
    "    model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "#load model\n",
    "if os.path.exists(model_path):\n",
    "    state = torch.load(str(model_path))\n",
    "    epoch = state['epoch']\n",
    "    step = state['step']\n",
    "    model.load_state_dict(state['model'])\n",
    "    print('Restored model, epoch {}, step {:,}'.format(epoch, step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 3333, 4579), True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_2m.shape, torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try to the full dataset\n",
    "# input_img = torch.unsqueeze(variable(dg_dataset[test_ind], volatile=True), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "img_arr = img_2m[[1,2,4], :2048,:2048].compute() #BGR\n",
    "# img_arr = img_2m[:, :2048,:2048].compute() # all 8\n",
    "img_arr = img_transform(torch.from_numpy(img_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/segmentation/IS_segmentation/utils.py:16: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return cuda(Variable(x, volatile=volatile))\n"
     ]
    }
   ],
   "source": [
    "input_img = torch.unsqueeze(variable(img_arr, volatile=True), dim=0)\n",
    "del img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.cpu()\n",
    "# big_mask = model(input_img.cpu())\n",
    "\n",
    "big_mask = model(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 2048)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_mask.cpu().detach().numpy().squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write out with gdal\n",
    "import gdal, osr\n",
    "\n",
    "def array2raster(newRasterfn,rasterOrigin,pixelWidth,pixelHeight,array):\n",
    "\n",
    "    cols = array.shape[1]\n",
    "    rows = array.shape[0]\n",
    "    originX = rasterOrigin[0]\n",
    "    originY = rasterOrigin[1]\n",
    "\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    outRaster = driver.Create(newRasterfn, cols, rows, 1, gdal.GDT_Float32)\n",
    "    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))\n",
    "    outband = outRaster.GetRasterBand(1)\n",
    "    outband.WriteArray(array)\n",
    "    outRasterSRS = osr.SpatialReference()\n",
    "    outRasterSRS.ImportFromEPSG(4326)\n",
    "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
    "    outband.FlushCache()\n",
    "    \n",
    "rname = 'runs/debug/test_eval_BGR_2015_renorm.tif'\n",
    "aff = img_2m.affine\n",
    "raster_origin = (aff.c, aff.f)\n",
    "pixel_height = aff.e\n",
    "pixel_width = aff.a\n",
    "array2raster(rname, raster_origin, pixel_width, pixel_height, big_mask.cpu().detach().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "big_mask_arr = big_mask.detach().numpy().squeeze()\n",
    "big_mask_arr_bin = big_mask_arr.copy()\n",
    "big_mask_arr_bin[big_mask_arr > 0] = 1\n",
    "big_mask_arr_bin[big_mask_arr <= 0] = 0\n",
    "plt.imshow(big_mask_arr_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spatial_torch35)",
   "language": "python",
   "name": "spatial_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
