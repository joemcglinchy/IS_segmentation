{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/spatial_torch/lib/python3.5/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/spatial_torch/lib/python3.5/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/spatial_torch/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/spatial_torch/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/spatial_torch/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import glob\n",
    "import os,sys\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import fiona\n",
    "from shapely.geometry import shape\n",
    "import shapely\n",
    "from rasterio.mask import mask\n",
    "from pyproj import Proj, transform\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from unet_models import unet11\n",
    "\n",
    "from test_unet_helpers import calcXYfromRC, checkWindow, gtDatasetSampler2, DigitalGlobeSamplerTensor\n",
    "\n",
    "from utils import variable\n",
    "from scipy import misc\n",
    "\n",
    "from gbdxtools import Interface, CatalogImage\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify scene id for DG data\n",
    "dg_scene_id = '1030010057062200' # 2016\n",
    "dg_scene_id = '104001000AA4B500' # 2015\n",
    "dg_scene_id = '103001001A425F00' #napoli 2011\n",
    "\n",
    "# specify image for 2.0 meter analysis\n",
    "gt_image_2 = '../rasters/union_impervious_raster_2_0_0_wgs84.tif' # desktop\n",
    "\n",
    "# specify images for 0.5 meter analysis\n",
    "gt_image_05 = '../rasters/union_impervious_raster_0_5.tif' # desktop\n",
    "\n",
    "# specify the shapefile\n",
    "shpfile = '../union/union.shp' # desktop\n",
    "\n",
    "with fiona.open(shpfile) as shp:\n",
    "    crs = shp.crs\n",
    "    shp_bounds = shp.bounds\n",
    "    shp_bounds = (14.159864978661743, 40.81140987011493, 14.302707008009895, 40.95396890196416) # napoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(img_2m, axis=(1,2)).compute(), np.std(img_2m, axis=(1,2)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_2m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8011, 8027)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1778.3651, 1471.3092, 1332.41  , 1282.5905, 1307.1593, 1605.073 ,\n",
       "        2170.9192, 1764.1276], dtype=float32),\n",
       " array([ 436.0207 ,  525.4969 ,  592.20544,  692.15497,  791.4114 ,\n",
       "         763.92255, 1115.3463 ,  936.5292 ], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to gbdx\n",
    "gbdx = Interface()\n",
    "\n",
    "# get the dask array for the 8 band MS image\n",
    "img_2m = CatalogImage(dg_scene_id, band_type='MS', bbox=shp_bounds, acomp=True)\n",
    "rows, cols = img_2m.shape[1:]\n",
    "print(img_2m.shape)\n",
    "np.mean(img_2m, axis=(1,2)).compute(), np.std(img_2m, axis=(1,2)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify image transform for RGB image\n",
    "img_transform = Compose([\n",
    "    Normalize(mean=[1630.7322, 1574.9552, 1549.1031], std=[837.0847 , 766.4114 , 604.51605])\n",
    "])\n",
    "\n",
    "# for 2015\n",
    "img_transform = Compose([\n",
    "    Normalize(mean=[1281.2312, 1243.6267, 1334.2975], std=[645.607, 703.0832, 862.68665])\n",
    "])\n",
    "\n",
    "# for 2011 Napoli image\n",
    "img_transform = Compose([\n",
    "    Normalize(mean=[1471.3092, 1332.41, 1307.1593], std=[525.4969, 592.20544, 692.15497])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and the model state from the .pt file. It may need to be downloaded from AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model, epoch 44, step 537\n"
     ]
    }
   ],
   "source": [
    "model_path = 'runs/debug/model_e100_b32_no_aug_GPUPAR.pt' # RGB batch size 32\n",
    "model_path = 'runs/debug/model_e100_b8_no_aug_GPUPAR.pt' # RGB batch size 8\n",
    "model_path = 'runs/debug/MS_model_e100_b8_no_aug_GPUPAR.pt' # MS model\n",
    "model_path = 'runs/debug/model_e44_s34938.pt' # RGB early exit (large batch size, i think)\n",
    "\n",
    "model = unet11(pretrained=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # get device for gpu or cpu\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    \n",
    "elif torch.cuda.is_available():\n",
    "    model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "#load model\n",
    "if os.path.exists(model_path):\n",
    "    state = torch.load(str(model_path))\n",
    "    epoch = state['epoch']\n",
    "    step = state['step']\n",
    "    model.load_state_dict(state['model'])\n",
    "    print('Restored model, epoch {}, step {:,}'.format(epoch, step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 8011, 8027), True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_2m.shape, torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try to the full dataset\n",
    "# input_img = torch.unsqueeze(variable(dg_dataset[test_ind], volatile=True), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "img_arr = img_2m[[1,2,4], :2048,:2048].compute() #BGR\n",
    "# img_arr = img_2m[:, :2048,:2048].compute() # all 8\n",
    "img_arr = img_transform(torch.from_numpy(img_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/segmentation/IS_segmentation/utils.py:16: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return cuda(Variable(x, volatile=volatile))\n"
     ]
    }
   ],
   "source": [
    "input_img = torch.unsqueeze(variable(img_arr, volatile=True), dim=0)\n",
    "del img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.cpu()\n",
    "# big_mask = model(input_img.cpu())\n",
    "\n",
    "big_mask = model(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 2048)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_mask.cpu().detach().numpy().squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write out with gdal\n",
    "import gdal, osr\n",
    "\n",
    "def array2raster(newRasterfn,rasterOrigin,pixelWidth,pixelHeight,array):\n",
    "\n",
    "    cols = array.shape[1]\n",
    "    rows = array.shape[0]\n",
    "    originX = rasterOrigin[0]\n",
    "    originY = rasterOrigin[1]\n",
    "\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    outRaster = driver.Create(newRasterfn, cols, rows, 1, gdal.GDT_Float32)\n",
    "    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))\n",
    "    outband = outRaster.GetRasterBand(1)\n",
    "    outband.WriteArray(array)\n",
    "    outRasterSRS = osr.SpatialReference()\n",
    "    outRasterSRS.ImportFromEPSG(4326)\n",
    "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
    "    outband.FlushCache()\n",
    "    \n",
    "rname = 'runs/debug/napoli_test_eval_BGR_2011.tif'\n",
    "aff = img_2m.affine\n",
    "raster_origin = (aff.c, aff.f)\n",
    "pixel_height = aff.e\n",
    "pixel_width = aff.a\n",
    "array2raster(rname, raster_origin, pixel_width, pixel_height, big_mask.cpu().detach().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "big_mask_arr = big_mask.detach().numpy().squeeze()\n",
    "big_mask_arr_bin = big_mask_arr.copy()\n",
    "big_mask_arr_bin[big_mask_arr > 0] = 1\n",
    "big_mask_arr_bin[big_mask_arr <= 0] = 0\n",
    "plt.imshow(big_mask_arr_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_ids = [u'1030010056565000',\n",
    "  u'103005004AF92E00',\n",
    "  u'1030050034F99000',\n",
    "  u'1030010003390200',\n",
    "  u'1030010007914D00',\n",
    "  u'10300100048FDE00',\n",
    "  u'103001002CB22C00',\n",
    "  u'103001002480AC00',\n",
    "  u'1030010024043000',\n",
    "  u'10300100254DF300',\n",
    "  u'10300100266A6200',\n",
    "  u'10300100267ACD00',\n",
    "  u'10300100252EBE00',\n",
    "  u'103001001E10B700',\n",
    "  u'1030010010AF3000',\n",
    "  u'1030010010429400',\n",
    "  u'103001000ED36500',\n",
    "  u'103001000F3D1D00',\n",
    "  u'103001000D952D00',\n",
    "  u'103001000FD5E300',\n",
    "  u'103001000FD41000',\n",
    "  u'10300100088CF100',\n",
    "  u'1030010010205A00',\n",
    "  u'1030010010B5F700',\n",
    "  u'1030010012D61500',\n",
    "  u'1030010012B84D00',\n",
    "  u'10300100104F0B00',\n",
    "  u'1030010011A83400',\n",
    "  u'1030010010965400',\n",
    "  u'1030010019087B00',\n",
    "  u'103001001D438400',\n",
    "  u'1030010010BCF200',\n",
    "  u'103001001DB85200',\n",
    "  u'103001001E11FB00',\n",
    "  u'10300100187B1F00',\n",
    "  u'103001001A425F00',\n",
    "  u'103001001ABE2000',\n",
    "  u'103001001ACB8500']\n",
    "\n",
    "dg_dates = [u'2016-05-19T10:02:40.151Z',\n",
    "  u'2016-04-06T09:49:07.389Z',\n",
    "  u'2014-10-06T10:08:32.167Z',\n",
    "  u'2010-02-01T09:58:57.200Z',\n",
    "  u'2010-09-19T10:23:29.763Z',\n",
    "  u'2010-03-14T10:04:17.721Z',\n",
    "  u'2014-03-03T10:11:36.261Z',\n",
    "  u'2013-06-26T10:18:35.209Z',\n",
    "  u'2013-06-26T10:18:23.514Z',\n",
    "  u'2013-07-23T10:22:50.466Z',\n",
    "  u'2013-08-11T10:21:48.153Z',\n",
    "  u'2013-08-22T10:15:37.287Z',\n",
    "  u'2013-08-03T10:16:47.951Z',\n",
    "  u'2013-01-06T10:18:53.821Z',\n",
    "  u'2011-12-20T10:29:03.008Z',\n",
    "  u'2011-12-31T10:24:33.624Z',\n",
    "  u'2011-11-12T10:25:46.383Z',\n",
    "  u'2011-11-20T10:31:50.994Z',\n",
    "  u'2011-08-17T10:18:39.418Z',\n",
    "  u'2011-11-15T10:15:40.186Z',\n",
    "  u'2011-12-01T10:27:39.012Z',\n",
    "  u'2011-01-13T10:10:29.597Z',\n",
    "  u'2011-12-23T10:18:49.813Z',\n",
    "  u'2012-01-19T10:25:39.551Z',\n",
    "  u'2012-04-04T10:28:13.432Z',\n",
    "  u'2012-03-27T10:22:50.220Z',\n",
    "  u'2012-01-30T10:21:00.566Z',\n",
    "  u'2012-01-27T10:31:17.962Z',\n",
    "  u'2012-01-08T10:30:27.435Z',\n",
    "  u'2012-04-26T10:18:05.764Z',\n",
    "  u'2012-12-26T10:24:28.605Z',\n",
    "  u'2012-01-11T10:20:00.939Z',\n",
    "  u'2012-11-26T10:29:57.162Z',\n",
    "  u'2012-12-26T10:24:18.205Z',\n",
    "  u'2012-05-12T10:28:26.586Z',\n",
    "  u'2012-07-27T10:28:45.976Z',\n",
    "  u'2012-07-19T10:23:21.164Z',\n",
    "  u'2012-07-11T10:18:30.952Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal, osr\n",
    "\n",
    "def array2raster(newRasterfn,rasterOrigin,pixelWidth,pixelHeight,array):\n",
    "\n",
    "    cols = array.shape[1]\n",
    "    rows = array.shape[0]\n",
    "    originX = rasterOrigin[0]\n",
    "    originY = rasterOrigin[1]\n",
    "\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    outRaster = driver.Create(newRasterfn, cols, rows, 1, gdal.GDT_Float32)\n",
    "    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))\n",
    "    outband = outRaster.GetRasterBand(1)\n",
    "    outband.WriteArray(array)\n",
    "    outRasterSRS = osr.SpatialReference()\n",
    "    outRasterSRS.ImportFromEPSG(4326)\n",
    "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
    "    outband.FlushCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model, epoch 44, step 537\n"
     ]
    }
   ],
   "source": [
    "model_path = 'runs/debug/model_e44_s34938.pt' # RGB early exit (large batch size, i think)\n",
    "\n",
    "model = unet11(pretrained=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # get device for gpu or cpu\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    \n",
    "elif torch.cuda.is_available():\n",
    "    model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "#load model\n",
    "if os.path.exists(model_path):\n",
    "    state = torch.load(str(model_path))\n",
    "    epoch = state['epoch']\n",
    "    step = state['step']\n",
    "    model.load_state_dict(state['model'])\n",
    "    print('Restored model, epoch {}, step {:,}'.format(epoch, step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030010056565000 2016-05-19T10:02:40.151Z (8, 8406, 8422)\n",
      "calculating stats\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/segmentation/IS_segmentation/utils.py:16: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return cuda(Variable(x, volatile=volatile))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103005004AF92E00 2016-04-06T09:49:07.389Z (8, 8093, 8108)\n",
      "calculating stats\n",
      "\n",
      "1030050034F99000 2014-10-06T10:08:32.167Z (8, 8122, 8137)\n",
      "calculating stats\n",
      "\n",
      "1030010003390200 2010-02-01T09:58:57.200Z (8, 8257, 8273)\n",
      "calculating stats\n",
      "\n",
      "1030010007914D00 2010-09-19T10:23:29.763Z (8, 7998, 8014)\n",
      "calculating stats\n",
      "\n",
      "10300100048FDE00 2010-03-14T10:04:17.721Z (8, 8379, 8395)\n",
      "calculating stats\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/spatial_torch/lib/python3.5/site-packages/gbdxtools/images/meta.py:440: UserWarning: Image does not contain specified geometry (14.159864978661743, 40.81140987011493, 14.302707008009895, 40.95396890196416) not in (14.13556568, 40.813414884275964, 14.341639215752783, 40.95218418)\n",
      "  warnings.warn(ae.args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103001002CB22C00 2014-03-03T10:11:36.261Z (8, 8189, 8205)\n",
      "calculating stats\n",
      "\n",
      "103001002480AC00 2013-06-26T10:18:35.209Z (8, 8167, 8184)\n",
      "calculating stats\n",
      "\n",
      "1030010024043000 2013-06-26T10:18:23.514Z (8, 8379, 8395)\n",
      "calculating stats\n",
      "\n",
      "10300100254DF300 2013-07-23T10:22:50.466Z (8, 8193, 8209)\n",
      "calculating stats\n",
      "\n",
      "10300100266A6200 2013-08-11T10:21:48.153Z (8, 8027, 8043)\n",
      "calculating stats\n",
      "\n",
      "10300100267ACD00 2013-08-22T10:15:37.287Z (8, 8239, 8256)\n",
      "calculating stats\n",
      "\n",
      "10300100252EBE00 2013-08-03T10:16:47.951Z (8, 8240, 8256)\n",
      "calculating stats\n",
      "\n",
      "103001001E10B700 2013-01-06T10:18:53.821Z (8, 8379, 8396)\n",
      "calculating stats\n",
      "\n",
      "1030010010AF3000 2011-12-20T10:29:03.008Z (8, 8266, 8282)\n",
      "calculating stats\n",
      "\n",
      "1030010010429400 2011-12-31T10:24:33.624Z (8, 8477, 8495)\n",
      "calculating stats\n",
      "\n",
      "103001000ED36500 2011-11-12T10:25:46.383Z (8, 8428, 8444)\n",
      "calculating stats\n",
      "\n",
      "103001000F3D1D00 2011-11-20T10:31:50.994Z (8, 8019, 8035)\n",
      "calculating stats\n",
      "\n",
      "103001000D952D00 2011-08-17T10:18:39.418Z (8, 8482, 8498)\n",
      "calculating stats\n",
      "\n",
      "103001000FD5E300 2011-11-15T10:15:40.186Z (8, 8318, 8334)\n",
      "calculating stats\n",
      "\n",
      "103001000FD41000 2011-12-01T10:27:39.012Z (8, 8344, 8360)\n",
      "calculating stats\n",
      "\n",
      "10300100088CF100 2011-01-13T10:10:29.597Z (8, 8313, 8330)\n",
      "calculating stats\n",
      "\n",
      "1030010010205A00 2011-12-23T10:18:49.813Z (8, 8441, 8458)\n",
      "calculating stats\n",
      "\n",
      "1030010010B5F700 2012-01-19T10:25:39.551Z (8, 8464, 8481)\n",
      "calculating stats\n",
      "\n",
      "1030010012D61500 2012-04-04T10:28:13.432Z (8, 8374, 8391)\n",
      "calculating stats\n",
      "\n",
      "1030010012B84D00 2012-03-27T10:22:50.220Z (8, 8510, 8526)\n",
      "calculating stats\n",
      "\n",
      "10300100104F0B00 2012-01-30T10:21:00.566Z (8, 8505, 8521)\n",
      "calculating stats\n",
      "\n",
      "1030010011A83400 2012-01-27T10:31:17.962Z (8, 8143, 8159)\n",
      "calculating stats\n",
      "\n",
      "1030010010965400 2012-01-08T10:30:27.435Z (8, 8097, 8112)\n",
      "calculating stats\n",
      "\n",
      "1030010019087B00 2012-04-26T10:18:05.764Z (8, 8365, 8382)\n",
      "calculating stats\n",
      "\n",
      "103001001D438400 2012-12-26T10:24:28.605Z (8, 8441, 8458)\n",
      "calculating stats\n",
      "\n",
      "1030010010BCF200 2012-01-11T10:20:00.939Z (8, 8477, 8495)\n",
      "calculating stats\n",
      "\n",
      "103001001DB85200 2012-11-26T10:29:57.162Z (8, 8326, 8342)\n",
      "calculating stats\n",
      "\n",
      "103001001E11FB00 2012-12-26T10:24:18.205Z (8, 8509, 8526)\n",
      "calculating stats\n",
      "\n",
      "10300100187B1F00 2012-05-12T10:28:26.586Z (8, 8379, 8396)\n",
      "calculating stats\n",
      "\n",
      "103001001A425F00 2012-07-27T10:28:45.976Z (8, 8011, 8027)\n",
      "calculating stats\n",
      "\n",
      "103001001ABE2000 2012-07-19T10:23:21.164Z (8, 8514, 8531)\n",
      "calculating stats\n",
      "\n",
      "103001001ACB8500 2012-07-11T10:18:30.952Z (8, 8283, 8300)\n",
      "calculating stats\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# connect to gbdx\n",
    "gbdx = Interface()\n",
    "shp_bounds = (14.159864978661743, 40.81140987011493, 14.302707008009895, 40.95396890196416) # napoli\n",
    "\n",
    "for d_id, d_dt in zip(dg_ids, dg_dates):\n",
    "    \n",
    "    try:\n",
    "        # get the dask array for the 8 band MS image\n",
    "        img_2m = CatalogImage(d_id, band_type='MS', bbox=shp_bounds, acomp=True)\n",
    "        rows, cols = img_2m.shape[1:]\n",
    "        print(d_id, d_dt, img_2m.shape)\n",
    "        print('calculating stats\\n')\n",
    "        \n",
    "        stats = img_2m.display_stats\n",
    "        means = stats['mean']\n",
    "        stds = stats['sigma']\n",
    "\n",
    "        # construct the normalization transform\n",
    "        img_transform = Compose([\n",
    "            Normalize(mean=torch.Tensor([means[1], means[2], means[4]]), std=torch.Tensor([stds[1], stds[2], stds[4]]))\n",
    "        ])\n",
    "\n",
    "        # subset the image array\n",
    "        img_arr = img_2m[[1,2,4], :2048,:2048].compute() #BGR\n",
    "        img_arr = img_transform(torch.from_numpy(img_arr))\n",
    "\n",
    "        # convert to torch\n",
    "        input_img = torch.unsqueeze(variable(img_arr, volatile=True), dim=0)\n",
    "        del img_arr\n",
    "\n",
    "        # inference\n",
    "        big_mask = model(input_img)\n",
    "\n",
    "\n",
    "        ## write out with gdal\n",
    "        rname = 'runs/debug/napoli_{}_{}_test_eval_BGR.tif'.format(d_id, d_dt[0:10])\n",
    "        aff = img_2m.affine\n",
    "        raster_origin = (aff.c, aff.f)\n",
    "        pixel_height = aff.e\n",
    "        pixel_width = aff.a\n",
    "        array2raster(rname, raster_origin, pixel_width, pixel_height, big_mask.cpu().detach().numpy().squeeze())\n",
    "        \n",
    "        del input_img\n",
    "        del img_2m\n",
    "        del big_mask\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('something happened with image {}, passing...'.format(d_id))\n",
    "        torch.cuda.empty_cache()\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spatial_torch35)",
   "language": "python",
   "name": "spatial_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
